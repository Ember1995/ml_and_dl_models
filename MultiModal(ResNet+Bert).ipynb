{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-22T16:02:52.394646Z",
     "iopub.status.busy": "2024-12-22T16:02:52.394292Z",
     "iopub.status.idle": "2024-12-22T16:03:05.512672Z",
     "shell.execute_reply": "2024-12-22T16:03:05.511730Z",
     "shell.execute_reply.started": "2024-12-22T16:02:52.394617Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Використовуваний пристрій: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Основні інструменти PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Оптимізація\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# Для тексту\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# BERT з HuggingFace\n",
    "!pip install --quiet transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Для ресемплінгу, векторизації та масштабування\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Для метрик\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#  НАЛАШТУВАННЯ CUDA \n",
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Використовуваний пристрій:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:03:05.514212Z",
     "iopub.status.busy": "2024-12-22T16:03:05.513824Z",
     "iopub.status.idle": "2024-12-22T16:03:05.652829Z",
     "shell.execute_reply": "2024-12-22T16:03:05.651861Z",
     "shell.execute_reply.started": "2024-12-22T16:03:05.514189Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Приклад з train.csv:\n",
      "        PetID                                        Description  AdoptionSpeed\n",
      "0  d3b4f29f8  Mayleen and Flo are two lovely adorable sister...              2\n",
      "1  e9dc82251  A total of 5 beautiful Tabbys available for ad...              2\n",
      "2  8111f6d4a  Two-and-a-half month old girl. Very manja and ...              2\n",
      "3  693a90fda  Neil is a healthy and active ~2-month-old fema...              2\n",
      "4  9d08c85ef  Gray kitten available for adoption in sungai p...              2 \n",
      "\n",
      "Приклад з test.csv:\n",
      "        PetID                                        Description\n",
      "0  6697a7f62  This cute little puppy is looking for a loving...\n",
      "1  23b64fe21  These 3 puppies was rescued from a mechanic sh...\n",
      "2  41e824cbe  Ara needs a forever home! Believe me, he's a r...\n",
      "3  6c3d7237b  i rescue this homeless dog 2 years ago but my ...\n",
      "4  97b0b5d92  We found him at a shopping mall at a very clea... \n",
      "\n",
      "Розподіл класів після балансування:\n",
      " AdoptionSpeed\n",
      "0    2133\n",
      "1    2133\n",
      "2    2133\n",
      "3    2133\n",
      "Name: count, dtype: int64\n",
      "Розмір даних після балансування: (8532, 3)\n"
     ]
    }
   ],
   "source": [
    "# ЧИТАННЯ ТА ПОПЕРЕДНЯ ОБРОБКА CSV\n",
    "data_path = '/kaggle/input/petfinder/'\n",
    "train_csv = os.path.join(data_path, 'train.csv')\n",
    "test_csv = os.path.join(data_path, 'test.csv')\n",
    "\n",
    "data_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "print(\"Приклад з train.csv:\\n\", data_df.head(), \"\\n\")\n",
    "print(\"Приклад з test.csv:\\n\", test_df.head(), \"\\n\")\n",
    "\n",
    "# Зсув цільового класу AdoptionSpeed з [1..4] до [0..3]\n",
    "data_df['AdoptionSpeed'] = data_df['AdoptionSpeed'] - 1\n",
    "\n",
    "# Заповнення пропусків в описі\n",
    "data_df['Description'].fillna(\"\", inplace=True)\n",
    "\n",
    "# Балансування\n",
    "max_count = data_df['AdoptionSpeed'].value_counts().max()\n",
    "resampled_data = []\n",
    "\n",
    "for speed in data_df['AdoptionSpeed'].unique():\n",
    "    class_df = data_df[data_df['AdoptionSpeed'] == speed]\n",
    "    class_resampled = resample(\n",
    "        class_df,\n",
    "        replace=True,\n",
    "        n_samples=max_count,\n",
    "        random_state=42\n",
    "    )\n",
    "    resampled_data.append(class_resampled)\n",
    "\n",
    "data_df = pd.concat(resampled_data, axis=0).reset_index(drop=True)\n",
    "print(\"Розподіл класів після балансування:\\n\",\n",
    "      data_df['AdoptionSpeed'].value_counts().sort_index())\n",
    "print(\"Розмір даних після балансування:\", data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:03:05.654824Z",
     "iopub.status.busy": "2024-12-22T16:03:05.654591Z",
     "iopub.status.idle": "2024-12-22T16:03:44.335479Z",
     "shell.execute_reply": "2024-12-22T16:03:44.334574Z",
     "shell.execute_reply.started": "2024-12-22T16:03:05.654804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ПОПЕРЕДНЯ ОБРОБКА ТЕКСТУ ТА ПІДГОТОВКА ДО BERT\n",
    "stop_words = set(stopwords.words('english'))\n",
    "negations = {\n",
    "    \"aren't\", \"isn't\", \"wasn't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\",\n",
    "    \"won't\", \"wouldn't\", \"don't\", \"doesn't\", \"didn't\", \"can't\", \"cannot\",\n",
    "    \"couldn't\", \"shouldn't\", \"mightn't\", \"mustn't\", \"not\", \"no\", \"nor\"\n",
    "}\n",
    "stop_words = stop_words.difference(negations)\n",
    "\n",
    "contractions = {\n",
    "    \"aren't\": \"are not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"no\": \"no\",\n",
    "    \"not\": \"not\",\n",
    "    \"nor\": \"nor\"\n",
    "}\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def normalize_text(raw_review):\n",
    "    # Прибираємо HTML-теги, email-адреси та посилання\n",
    "    text = re.sub(\"<[^>]*>\", \" \", raw_review)\n",
    "    text = re.sub(\"\\\\S*@\\\\S*[\\\\s]+\", \" \", text)\n",
    "    text = re.sub(\"https?://.*?[\\\\s]+\", \" \", text)\n",
    "    \n",
    "    # Розділяємо на слова (lower)\n",
    "    text = text.lower().split()\n",
    "    # Розкриваємо скорочення\n",
    "    text = [contractions.get(word, word) for word in text]\n",
    "    # Прибираємо стоп-слова (крім negations)\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    \n",
    "    # З’єднуємо назад\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # Лематизація через spaCy\n",
    "    doc = nlp(text)\n",
    "    text = \" \".join([token.lemma_ for token in doc if len(token.lemma_) > 1])\n",
    "    \n",
    "    # Прибираємо зайві пробіли\n",
    "    text = re.sub(\"[\\\\s]+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "data_df[\"Description\"] = data_df[\"Description\"].apply(normalize_text)\n",
    "\n",
    "# Ці колонки будемо передавати в BERT\n",
    "X_text = data_df[\"Description\"]\n",
    "y_text = data_df[\"AdoptionSpeed\"]\n",
    "pet_ids_text = data_df[\"PetID\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:03:44.337102Z",
     "iopub.status.busy": "2024-12-22T16:03:44.336823Z",
     "iopub.status.idle": "2024-12-22T16:04:19.858881Z",
     "shell.execute_reply": "2024-12-22T16:04:19.857920Z",
     "shell.execute_reply.started": "2024-12-22T16:03:44.337067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e2e27a26ad467baf6ccb9b137b784f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dc9bcd72d540599b45d0c0cfc9d451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742ffaccdb3143f69305bb71d33b2906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9dd45701ee45ab9108e18a5eabf4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d54440c0184fd28dfa8291682dfc10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма BERT-фіч для train: (8532, 768)\n"
     ]
    }
   ],
   "source": [
    "# ФУНКЦІЇ ТА КЛАСИ ДЛЯ ОТРИМАННЯ EMBEDDINGS ВІД BERT\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "bert_model = AutoModel.from_pretrained(PRETRAINED_MODEL_NAME).to(device)\n",
    "\n",
    "# Щоб обчислювати ембеддинги, створимо Dataset і функцію, \n",
    "# яка вертатиме вектор для кожного речення.\n",
    "class TextDatasetBERT(Dataset):\n",
    "    def __init__(self, texts, max_len=128):\n",
    "        \"\"\"\n",
    "        texts: список попередньо оброблених рядків (з лематизацією).\n",
    "        max_len: максимальна довжина для BERT (токенів).\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }\n",
    "\n",
    "def extract_bert_features(model, dataset, batch_size=16):\n",
    "    \"\"\"\n",
    "    model: BERT-модель (AutoModel) із transformers\n",
    "    dataset: TextDatasetBERT\n",
    "    Повертає масив розмірністю [N, hidden_size], де hidden_size = 768 (для bert-base-uncased).\n",
    "    Використовуємо CLS-токен (first token) як вектор речення.\n",
    "    \"\"\"\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    all_features = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            # outputs.last_hidden_state: [batch_size, seq_len, hidden_size]\n",
    "            # Візьмемо [CLS] токен = позиція 0\n",
    "            cls_embeds = outputs.last_hidden_state[:, 0, :]  # [batch_size, 768]\n",
    "            all_features.append(cls_embeds.cpu().numpy())\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    return all_features\n",
    "\n",
    "# Витягаємо BERT-вектори для train\n",
    "text_dataset_train = TextDatasetBERT(X_text.tolist(), max_len=128)\n",
    "X_text_bert = extract_bert_features(bert_model, text_dataset_train, batch_size=16)\n",
    "print(\"Форма BERT-фіч для train:\", X_text_bert.shape)\n",
    "\n",
    "# Масштабуємо (MinMaxScaler), аби було узгоджено з image-фічами\n",
    "scaler_text = MinMaxScaler()\n",
    "X_text_bert_scaled = scaler_text.fit_transform(X_text_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:04:19.860256Z",
     "iopub.status.busy": "2024-12-22T16:04:19.859810Z",
     "iopub.status.idle": "2024-12-22T16:04:59.446786Z",
     "shell.execute_reply": "2024-12-22T16:04:59.445729Z",
     "shell.execute_reply.started": "2024-12-22T16:04:19.860235Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Усього файлів у папці train (зображень): 28472\n",
      "ImageTrainDataset: знайдено 8532 записів із картинками.\n"
     ]
    }
   ],
   "source": [
    "# ВИДІЛЕННЯ IMAGE-ФІЧ (ResNet) ТІЛЬКИ ДЛЯ НАЯВНИХ ЗОБРАЖЕНЬ\n",
    "base_image_dir = '/kaggle/input/petfinder/images/images/train'\n",
    "all_files = os.listdir(base_image_dir)\n",
    "print(f\"Усього файлів у папці train (зображень): {len(all_files)}\")\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class ImageTrainDataset(Dataset):\n",
    "    def __init__(self, data_df, image_dir, transform):\n",
    "        self.records = []\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        existing_files = set(os.listdir(image_dir))\n",
    "        \n",
    "        for i, row in data_df.iterrows():\n",
    "            pid = row['PetID']\n",
    "            label = row['AdoptionSpeed']\n",
    "            candidate = None\n",
    "            # Шукаємо хоча б один файл, який починається з PetID\n",
    "            for f in [f for f in existing_files if f.startswith(pid + \"-\")]:\n",
    "                candidate = f\n",
    "                break\n",
    "            if candidate is not None:\n",
    "                self.records.append((pid, label, candidate))\n",
    "        \n",
    "        print(f\"ImageTrainDataset: знайдено {len(self.records)} записів із картинками.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pid, label, fname = self.records[idx]\n",
    "        path = os.path.join(self.image_dir, fname)\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, pid\n",
    "\n",
    "train_img_dataset = ImageTrainDataset(data_df, base_image_dir, train_transforms)\n",
    "train_img_loader = DataLoader(train_img_dataset, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:04:59.448141Z",
     "iopub.status.busy": "2024-12-22T16:04:59.447840Z",
     "iopub.status.idle": "2024-12-22T16:08:21.820646Z",
     "shell.execute_reply": "2024-12-22T16:08:21.819598Z",
     "shell.execute_reply.started": "2024-12-22T16:04:59.448112Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 194MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] Loss: 1.3104 | Acc: 0.3807\n",
      "[Epoch 2/10] Loss: 1.2515 | Acc: 0.4269\n",
      "[Epoch 3/10] Loss: 1.2275 | Acc: 0.4522\n",
      "[Epoch 4/10] Loss: 1.2063 | Acc: 0.4661\n",
      "[Epoch 5/10] Loss: 1.1863 | Acc: 0.4752\n",
      "[Epoch 6/10] Loss: 1.1646 | Acc: 0.4823\n",
      "[Epoch 7/10] Loss: 1.1595 | Acc: 0.4886\n",
      "[Epoch 8/10] Loss: 1.1504 | Acc: 0.4989\n",
      "[Epoch 9/10] Loss: 1.1502 | Acc: 0.4958\n",
      "[Epoch 10/10] Loss: 1.1557 | Acc: 0.4895\n",
      "Найкраща втрата (ResNet): 1.1502\n"
     ]
    }
   ],
   "source": [
    "# Попередньо навчена ResNet50\n",
    "model_conv = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 4)  # 4 класи (0..3)\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion_img = nn.CrossEntropyLoss()\n",
    "optimizer_conv = optim.Adam(model_conv.fc.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer_conv, step_size=5, gamma=0.1)\n",
    "\n",
    "def train_resnet(model, loader, device, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    best_loss = float('inf')\n",
    "    best_path = '/kaggle/working/best_img_model.pt'\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels, pids in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(loader.dataset)\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "    \n",
    "    print(f\"Найкраща втрата (ResNet): {best_loss:.4f}\")\n",
    "    model.load_state_dict(torch.load(best_path))\n",
    "\n",
    "# Тренування ResNet на зображеннях\n",
    "train_resnet(model_conv, train_img_loader, device, criterion_img, optimizer_conv, scheduler, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:08:21.822207Z",
     "iopub.status.busy": "2024-12-22T16:08:21.821952Z",
     "iopub.status.idle": "2024-12-22T16:08:40.093017Z",
     "shell.execute_reply": "2024-12-22T16:08:40.091965Z",
     "shell.execute_reply.started": "2024-12-22T16:08:21.822184Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Витягнуто фічі для PetID (із картинками): 4542\n"
     ]
    }
   ],
   "source": [
    "def extract_resnet_features(model, loader):\n",
    "    model.eval()\n",
    "    feats_dict = {}\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, pids in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            # Проходимо шари ResNet, ОКРІМ фінального fc\n",
    "            x = model.conv1(inputs)\n",
    "            x = model.bn1(x)\n",
    "            x = model.relu(x)\n",
    "            x = model.maxpool(x)\n",
    "            x = model.layer1(x)\n",
    "            x = model.layer2(x)\n",
    "            x = model.layer3(x)\n",
    "            x = model.layer4(x)\n",
    "            x = model.avgpool(x)  # [batch_size, 2048, 1, 1]\n",
    "            x = torch.flatten(x, 1)  # => [batch_size, 2048]\n",
    "            \n",
    "            x_cpu = x.cpu().numpy()\n",
    "            for i, pid in enumerate(pids):\n",
    "                feats_dict[pid] = x_cpu[i]\n",
    "    return feats_dict\n",
    "\n",
    "# Витягаємо фічі з ResNet\n",
    "train_img_loader_extract = DataLoader(train_img_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "train_img_feats_dict = extract_resnet_features(model_conv, train_img_loader_extract)\n",
    "print(\"Витягнуто фічі для PetID (із картинками):\", len(train_img_feats_dict))\n",
    "\n",
    "all_img_features = np.array(list(train_img_feats_dict.values()))\n",
    "scaler_img = MinMaxScaler()\n",
    "all_img_features_scaled = scaler_img.fit_transform(all_img_features)\n",
    "\n",
    "# Зберігаємо назад в словник (нормалізовані фічі)\n",
    "for i, pid in enumerate(train_img_feats_dict.keys()):\n",
    "    train_img_feats_dict[pid] = all_img_features_scaled[i]\n",
    "\n",
    "image_feature_dim = all_img_features_scaled.shape[1]  # 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:08:40.094718Z",
     "iopub.status.busy": "2024-12-22T16:08:40.094329Z",
     "iopub.status.idle": "2024-12-22T16:08:40.220152Z",
     "shell.execute_reply": "2024-12-22T16:08:40.219229Z",
     "shell.execute_reply.started": "2024-12-22T16:08:40.094683Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загальна форма (комбіновані фічі): (8532, 2816)\n"
     ]
    }
   ],
   "source": [
    "# ЗБІР КОМБО: BERT-ТЕКСТ + (IMAGE або ZEROS)\n",
    "text_feature_dim = X_text_bert_scaled.shape[1]  # 768 (для bert-base-uncased)\n",
    "\n",
    "X_text_np = X_text_bert_scaled  # [N, 768]\n",
    "y_labels_np = y_text.values  # [N, ]\n",
    "pet_ids_all = pet_ids_text\n",
    "\n",
    "# Створюємо масив image-фіч\n",
    "X_image_np = np.zeros((len(pet_ids_all), image_feature_dim), dtype=np.float32)\n",
    "\n",
    "pid_to_idx = {pid: i for i, pid in enumerate(pet_ids_all)}\n",
    "for pid, feat in train_img_feats_dict.items():\n",
    "    if pid in pid_to_idx:\n",
    "        idx = pid_to_idx[pid]\n",
    "        X_image_np[idx] = feat.astype(np.float32)\n",
    "\n",
    "combined_feats = np.hstack([X_text_np, X_image_np])  # [N, 768 + 2048] = [N, 2816]\n",
    "print(\"Загальна форма (комбіновані фічі):\", combined_feats.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    combined_feats,\n",
    "    y_labels_np,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:08:40.223119Z",
     "iopub.status.busy": "2024-12-22T16:08:40.222881Z",
     "iopub.status.idle": "2024-12-22T16:08:40.241925Z",
     "shell.execute_reply": "2024-12-22T16:08:40.241029Z",
     "shell.execute_reply.started": "2024-12-22T16:08:40.223100Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ГЛИБОКА MLP-МОДЕЛЬ ІЗ 7 ШАРАМИ, DROPОUT, L2, SKIP CONNECTIONS + EARLY STOPPING\n",
    "class DeeperMultimodalModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Модель MLP із 7 прихованими шарами (fc1..fc7), batch norm,\n",
    "    dropout і skip-зв’язками (out_i -> fc_{i+1} + out_i).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_p=0.2):\n",
    "        super(DeeperMultimodalModel, self).__init__()\n",
    "        \n",
    "        # 1-й шар\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dp1 = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # 2-й шар\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dp2 = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # 3-й шар\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dp3 = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # 4-й шар\n",
    "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn4 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dp4 = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # 5-й шар\n",
    "        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn5 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dp5 = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # 6-й шар\n",
    "        self.fc6 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn6 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dp6 = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # 7-й шар\n",
    "        self.fc7 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn7 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dp7 = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # Фінальний\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1\n",
    "        out1 = F.relu(self.bn1(self.fc1(x)))\n",
    "        out1 = self.dp1(out1)\n",
    "        \n",
    "        # 2 + skip\n",
    "        out2 = self.fc2(out1)\n",
    "        out2 = F.relu(self.bn2(out2 + out1))\n",
    "        out2 = self.dp2(out2)\n",
    "        \n",
    "        # 3 + skip\n",
    "        out3 = self.fc3(out2)\n",
    "        out3 = F.relu(self.bn3(out3 + out2))\n",
    "        out3 = self.dp3(out3)\n",
    "        \n",
    "        # 4 + skip\n",
    "        out4 = self.fc4(out3)\n",
    "        out4 = F.relu(self.bn4(out4 + out3))\n",
    "        out4 = self.dp4(out4)\n",
    "        \n",
    "        # 5 + skip\n",
    "        out5 = self.fc5(out4)\n",
    "        out5 = F.relu(self.bn5(out5 + out4))\n",
    "        out5 = self.dp5(out5)\n",
    "        \n",
    "        # 6 + skip\n",
    "        out6 = self.fc6(out5)\n",
    "        out6 = F.relu(self.bn6(out6 + out5))\n",
    "        out6 = self.dp6(out6)\n",
    "        \n",
    "        # 7 + skip\n",
    "        out7 = self.fc7(out6)\n",
    "        out7 = F.relu(self.bn7(out7 + out6))\n",
    "        out7 = self.dp7(out7)\n",
    "        \n",
    "        # Фінальний\n",
    "        out = self.fc_out(out7)\n",
    "        return out\n",
    "\n",
    "mm_input_dim = combined_feats.shape[1]  # 2816 = 768(BERT) + 2048(ResNet)\n",
    "mm_hidden_dim = 128                     # 128 (гіперпараметр)\n",
    "mm_output_dim = 4                       # 4 класи (0..3)\n",
    "\n",
    "model_mm = DeeperMultimodalModel(mm_input_dim, mm_hidden_dim, mm_output_dim, dropout_p=0.35).to(device)\n",
    "\n",
    "criterion_mm = nn.CrossEntropyLoss()\n",
    "optimizer_mm = optim.Adam(model_mm.parameters(), lr=1e-3, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:08:40.243628Z",
     "iopub.status.busy": "2024-12-22T16:08:40.243340Z",
     "iopub.status.idle": "2024-12-22T16:08:50.458412Z",
     "shell.execute_reply": "2024-12-22T16:08:50.457537Z",
     "shell.execute_reply.started": "2024-12-22T16:08:40.243606Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] Train Loss: 1.4414 | Val Loss: 1.3825\n",
      "[Epoch 2/10] Train Loss: 1.4005 | Val Loss: 1.3809\n",
      "[Epoch 3/10] Train Loss: 1.3828 | Val Loss: 1.3731\n",
      "[Epoch 4/10] Train Loss: 1.3630 | Val Loss: 1.3629\n",
      "[Epoch 5/10] Train Loss: 1.3393 | Val Loss: 1.3541\n",
      "[Epoch 6/10] Train Loss: 1.3215 | Val Loss: 1.3573\n",
      "[Epoch 7/10] Train Loss: 1.2982 | Val Loss: 1.3334\n",
      "[Epoch 8/10] Train Loss: 1.2708 | Val Loss: 1.3175\n",
      "[Epoch 9/10] Train Loss: 1.2460 | Val Loss: 1.3087\n",
      "[Epoch 10/10] Train Loss: 1.2070 | Val Loss: 1.2844\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = SimpleDataset(X_train, y_train)\n",
    "val_ds = SimpleDataset(X_val, y_val)\n",
    "\n",
    "train_ld = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_ld = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "def evaluate_loss(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            out = model(Xb)\n",
    "            loss = criterion(out, yb)\n",
    "            batch_size = Xb.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_count += batch_size\n",
    "    return total_loss / total_count\n",
    "\n",
    "def train_multimodal_model_early_stopping(model, train_loader, val_loader, criterion, optimizer, \n",
    "                                          epochs=10, patience=2):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = \"/kaggle/working/best_mm_model.pt\"\n",
    "    no_improvement_count = 0\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for Xb, yb in train_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(Xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        val_loss = evaluate_loss(model, val_loader, criterion)\n",
    "        \n",
    "        print(f\"[Epoch {epoch}/{epochs}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Перевірка на покращення\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            no_improvement_count = 0\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "        \n",
    "        # Early Stopping\n",
    "        if no_improvement_count >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "def eval_multimodal_model(model, loader):\n",
    "    \"\"\" Повертаємо передбачення і справжні значення для обчислення метрик. \"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            out = model(Xb)\n",
    "            pred = torch.argmax(out, dim=1)\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "            trues.extend(yb.cpu().numpy())\n",
    "    return preds, trues\n",
    "\n",
    "# ---- Навчання моделі (з Early Stopping) ----\n",
    "train_multimodal_model_early_stopping(\n",
    "    model_mm,\n",
    "    train_ld,\n",
    "    val_ld,\n",
    "    criterion_mm,\n",
    "    optimizer_mm,\n",
    "    epochs=10,\n",
    "    patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:08:50.459680Z",
     "iopub.status.busy": "2024-12-22T16:08:50.459353Z",
     "iopub.status.idle": "2024-12-22T16:08:50.468026Z",
     "shell.execute_reply": "2024-12-22T16:08:50.467303Z",
     "shell.execute_reply.started": "2024-12-22T16:08:50.459646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Обчислення QWK\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    \"\"\"\n",
    "    rater_a = np.array(y, dtype=int)\n",
    "    rater_b = np.array(y_pred, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    min_rating = min(min(rater_a), min(rater_b))\n",
    "    max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:08:50.469052Z",
     "iopub.status.busy": "2024-12-22T16:08:50.468831Z",
     "iopub.status.idle": "2024-12-22T16:08:50.597963Z",
     "shell.execute_reply": "2024-12-22T16:08:50.597329Z",
     "shell.execute_reply.started": "2024-12-22T16:08:50.469020Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.64      0.48       428\n",
      "           1       0.34      0.37      0.36       445\n",
      "           2       0.42      0.20      0.27       423\n",
      "           3       0.52      0.41      0.46       411\n",
      "\n",
      "    accuracy                           0.41      1707\n",
      "   macro avg       0.42      0.41      0.39      1707\n",
      "weighted avg       0.42      0.41      0.39      1707\n",
      "\n",
      "Quadratic Weighted Kappa: 0.3177002357755254\n"
     ]
    }
   ],
   "source": [
    "#  Оцінка на валідації \n",
    "preds_val, trues_val = eval_multimodal_model(model_mm, val_ld)\n",
    "print(\"Validation report:\\n\", classification_report(trues_val, preds_val))\n",
    "print(\"Quadratic Weighted Kappa:\", quadratic_weighted_kappa(trues_val, preds_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:08:50.599095Z",
     "iopub.status.busy": "2024-12-22T16:08:50.598806Z",
     "iopub.status.idle": "2024-12-22T16:09:08.975950Z",
     "shell.execute_reply": "2024-12-22T16:09:08.975172Z",
     "shell.execute_reply.started": "2024-12-22T16:08:50.599065Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageTestDataset: знайдено 1887 зображень у тесті.\n"
     ]
    }
   ],
   "source": [
    "# ПЕРЕДБАЧЕННЯ НА TEST\n",
    "test_df[\"Description\"].fillna(\"\", inplace=True)\n",
    "test_df[\"Description\"] = test_df[\"Description\"].apply(normalize_text)\n",
    "\n",
    "# Створюємо BERT-фічі для тесту\n",
    "text_dataset_test = TextDatasetBERT(test_df[\"Description\"].tolist(), max_len=128)\n",
    "X_test_bert = extract_bert_features(bert_model, text_dataset_test, batch_size=16)\n",
    "X_test_bert_scaled = scaler_text.transform(X_test_bert)\n",
    "\n",
    "test_pet_ids = test_df[\"PetID\"].values\n",
    "\n",
    "test_image_dir = '/kaggle/input/petfinder/images/images/test'\n",
    "test_files = set(os.listdir(test_image_dir))\n",
    "\n",
    "class ImageTestDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform):\n",
    "        self.records = []\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        for i, row in df.iterrows():\n",
    "            pid = row['PetID']\n",
    "            candidate = None\n",
    "            for f in [f for f in test_files if f.startswith(pid + \"-\")]:\n",
    "                candidate = f\n",
    "                break\n",
    "            if candidate is not None:\n",
    "                self.records.append((pid, candidate))\n",
    "        \n",
    "        print(f\"ImageTestDataset: знайдено {len(self.records)} зображень у тесті.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pid, fname = self.records[idx]\n",
    "        path = os.path.join(self.image_dir, fname)\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, pid\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_img_dataset = ImageTestDataset(test_df, test_image_dir, test_transforms)\n",
    "test_img_loader = DataLoader(test_img_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:09:08.977033Z",
     "iopub.status.busy": "2024-12-22T16:09:08.976770Z",
     "iopub.status.idle": "2024-12-22T16:09:35.932135Z",
     "shell.execute_reply": "2024-12-22T16:09:35.931379Z",
     "shell.execute_reply.started": "2024-12-22T16:09:08.977011Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Витягнуто тестових image-фіч: 1887\n",
      "Форма комбінованого тесту: (1891, 2816)\n"
     ]
    }
   ],
   "source": [
    "# Витягаємо фічі ResNet для тесту\n",
    "model_conv.eval()\n",
    "def extract_test_image_features(model, loader, device):\n",
    "    feats_dict = {}\n",
    "    with torch.no_grad():\n",
    "        for images, pids in loader:\n",
    "            images = images.to(device)\n",
    "            x = model.conv1(images)\n",
    "            x = model.bn1(x)\n",
    "            x = model.relu(x)\n",
    "            x = model.maxpool(x)\n",
    "            x = model.layer1(x)\n",
    "            x = model.layer2(x)\n",
    "            x = model.layer3(x)\n",
    "            x = model.layer4(x)\n",
    "            x = model.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x_cpu = x.cpu().numpy()\n",
    "            for i, pid in enumerate(pids):\n",
    "                feats_dict[pid] = x_cpu[i]\n",
    "    return feats_dict\n",
    "\n",
    "test_img_feats_dict = extract_test_image_features(model_conv, test_img_loader, device)\n",
    "print(\"Витягнуто тестових image-фіч:\", len(test_img_feats_dict))\n",
    "\n",
    "# Нормалізуємо тестові image-фічі\n",
    "for pid, feat in test_img_feats_dict.items():\n",
    "    feat_2d = feat.reshape(1, -1)\n",
    "    scaled_feat = scaler_img.transform(feat_2d)\n",
    "    test_img_feats_dict[pid] = scaled_feat[0].astype(np.float32)\n",
    "\n",
    "# Збираємо комбіновані (BERT + image) фічі для тесту\n",
    "test_combined = []\n",
    "for i, row in test_df.iterrows():\n",
    "    pid = row['PetID']\n",
    "    txt_vec = X_test_bert_scaled[i]\n",
    "    # Якщо зображень немає, пишемо нулі\n",
    "    if pid in test_img_feats_dict:\n",
    "        img_vec = test_img_feats_dict[pid]\n",
    "    else:\n",
    "        img_vec = np.zeros(image_feature_dim, dtype=np.float32)\n",
    "    combined_vec = np.hstack([txt_vec, img_vec])\n",
    "    test_combined.append(combined_vec)\n",
    "\n",
    "test_combined = np.array(test_combined, dtype=np.float32)\n",
    "print(\"Форма комбінованого тесту:\", test_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:09:35.933483Z",
     "iopub.status.busy": "2024-12-22T16:09:35.933109Z",
     "iopub.status.idle": "2024-12-22T16:09:35.966703Z",
     "shell.execute_reply": "2024-12-22T16:09:35.965880Z",
     "shell.execute_reply.started": "2024-12-22T16:09:35.933447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл сабмішену збережено у: /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Передбачення\n",
    "model_mm.eval()\n",
    "with torch.no_grad():\n",
    "    test_tensor = torch.tensor(test_combined, dtype=torch.float32).to(device)\n",
    "    logits = model_mm(test_tensor)\n",
    "    preds_test = torch.argmax(logits, dim=1).cpu().numpy()  # 0..3\n",
    "\n",
    "# Повертаємо класи до [1..4]\n",
    "final_preds = preds_test + 1\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    \"PetID\": test_pet_ids,\n",
    "    \"AdoptionSpeed\": final_preds\n",
    "})\n",
    "\n",
    "save_path = '/kaggle/working/submission.csv'\n",
    "submission_df.to_csv(save_path, index=False)\n",
    "print(\"Файл сабмішену збережено у:\", save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6347763,
     "sourceId": 10261422,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
